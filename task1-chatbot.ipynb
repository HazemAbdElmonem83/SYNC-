{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Building a Simple Chatbot in Python using NLTK\n",
        "\n"
      ],
      "metadata": {
        "id": "2-Yzg_tAGINO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Import necessary libraries"
      ],
      "metadata": {
        "id": "RRZQdcXUGVfh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "import random\n",
        "import string # to process standard python strings\n",
        "import warnings\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "T3RAPKp-GcNf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Installing NLTK Packages"
      ],
      "metadata": {
        "id": "PXgVpaXCGgVA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('popular', quiet=True)\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PX6BS6UlGoma",
        "outputId": "22d4ff0a-36bf-45a0-85cd-dbb811edd91d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Reading in the corpus"
      ],
      "metadata": {
        "id": "GSMtIsmxGyYu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f=open('chatbot.txt','r',errors = 'ignore')\n",
        "raw=f.read()\n",
        "raw = raw.lower()"
      ],
      "metadata": {
        "id": "I1YHwuiXGu_8"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Tokenisation"
      ],
      "metadata": {
        "id": "esovgUu3HYHT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sent_tokens = nltk.sent_tokenize(raw)\n",
        "word_tokens = nltk.word_tokenize(raw)"
      ],
      "metadata": {
        "id": "BncXlAACHaF3"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Preprocessing"
      ],
      "metadata": {
        "id": "lOQj6mQiHfpR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lemmer = nltk.stem.WordNetLemmatizer()\n",
        "\n",
        "def LemTokens(tokens):\n",
        "    return [lemmer.lemmatize(token) for token in tokens]\n",
        "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
        "\n",
        "def LemNormalize(text):\n",
        "    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))"
      ],
      "metadata": {
        "id": "F4jC1odrHhDe"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Keyword matching"
      ],
      "metadata": {
        "id": "kxAcYm1XHqNT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "GREETING_INPUTS = (\"hello\", \"hi\", \"greetings\", \"sup\", \"what's up\",\"hey\",)\n",
        "GREETING_RESPONSES = [\"hi\", \"hey\", \"*nods*\", \"hi there\", \"hello\", \"I am glad! You are talking to me\"]\n",
        "def greeting(sentence):\n",
        "\n",
        "    for word in sentence.split():\n",
        "        if word.lower() in GREETING_INPUTS:\n",
        "            return random.choice(GREETING_RESPONSES)"
      ],
      "metadata": {
        "id": "daKR3vLsHpvk"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Cosine Similarity"
      ],
      "metadata": {
        "id": "1OTnIx62HvQL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def response(user_response):\n",
        "    robo_response=''\n",
        "    sent_tokens.append(user_response)\n",
        "    TfidfVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words='english')\n",
        "    tfidf = TfidfVec.fit_transform(sent_tokens)\n",
        "    vals = cosine_similarity(tfidf[-1], tfidf)\n",
        "    idx=vals.argsort()[0][-2]\n",
        "    flat = vals.flatten()\n",
        "    flat.sort()\n",
        "    req_tfidf = flat[-2]\n",
        "    if(req_tfidf==0):\n",
        "        robo_response=robo_response+\"I am sorry! I don't understand you\"\n",
        "        return robo_response\n",
        "    else:\n",
        "        robo_response = robo_response+sent_tokens[idx]\n",
        "        return robo_response"
      ],
      "metadata": {
        "id": "mS2gC9DkHu7v"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flag=True\n",
        "print(\"Squd: My name is squd. I will answer your queries about Chatbots. If you want to exit, type Bye!\")\n",
        "while(flag==True):\n",
        "    user_response = input()\n",
        "    user_response=user_response.lower()\n",
        "    if(user_response!='bye'):\n",
        "        if(user_response=='thanks' or user_response=='thank you' ):\n",
        "            flag=False\n",
        "            print(\"squd: You are welcome..\")\n",
        "        else:\n",
        "            if(greeting(user_response)!=None):\n",
        "                print(\"squd: \"+greeting(user_response))\n",
        "            else:\n",
        "                print(\"squd: \",end=\"\")\n",
        "                print(response(user_response))\n",
        "                sent_tokens.remove(user_response)\n",
        "    else:\n",
        "        flag=False\n",
        "        print(\"squd: Bye! take care..\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0YMP7oRH53_",
        "outputId": "b5759998-8335-4ce4-9aee-7f0ad4a057f0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Squd: My name is squd. I will answer your queries about Chatbots. If you want to exit, type Bye!\n",
            "hi\n",
            "squd: hey\n",
            "what is chatbot\n",
            "design\n",
            "the chatbot design is the process that defines the interaction between the user and the chatbot.the chatbot designer will define the chatbot personality, the questions that will be asked to the users, and the overall interaction.it can be viewed as a subset of the conversational design.\n",
            "how we can use chatbots\n",
            "company internal platforms\n",
            "other companies explore ways they can use chatbots internally, for example for customer support, human resources, or even in internet-of-things (iot) projects.\n",
            "bye\n",
            "squd: Bye! take care..\n"
          ]
        }
      ]
    }
  ]
}